---
layout: plain
title: "Reasoning with LLMs (UdS; Summer25/26)"

---

[//]: # (Course Title: Reasoning with LLMs: Techniques, Capabilities and Beyond)

### Course Description

Large Language Models (LLMs) have become powerful tools capable of performing
a wide range of human-like tasks, from translation to complex problem-solving.
However, reasoning—the ability to logically infer, plan, 
and generalize—remains a fundamental challenge that distinguishes them 
from human intelligence. While techniques like Chain-of-Thought prompting
and specialized training methods have significantly improved reasoning, 
the question of whether they can truly replicate human-like reasoning 
and how to approach it remains open 
In this seminar, we will explore recent advancements in reasoning with LLMs,
including techniques for improving their performance, 
analyses of how these models reason, and discussions on how to move
beyond current approaches.



### Prerequisites

Students should have a solid background in NLP and machine learning. 
Familiarity with language models, including how tasks are defined, 
common architectures such as GPT-2, and how these models are trained
to perform specific tasks, will be assumed. 


### Information

**Instructor:** [Yuekun Yao](https://ykyaol7.github.io/)


## Schedule & Reading List

Below is the **schedule for the course**. The readings are **subject to change**.


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
</head>
<body>


<div class="container mt-4">
    <table class="table table-striped table-bordered">
        <thead class="table-dark">
            <tr>
                <th>Topic</th>
                <th>Date</th>
                <th>Reading</th>
                <th>Discussion Leader</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td rowspan="2">Introduction</td>
                <td></td>
                <td></td>
                <td>Yuekun</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>Yuekun</td>
            </tr>
            <tr>
                <td>Benchmarks</td>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td rowspan="3">Inference</td>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td rowspan="2">Post-train</td>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td rowspan="3">Test-time Scaling</td>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td rowspan="2">Analysis</td>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
            <tr>
                <td>Limitations & Beyond</td>
                <td></td>
                <td></td>
                <td>TBD</td>
            </tr>
        </tbody>
    </table>
</div>

</body>
</html>